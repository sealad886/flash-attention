name: Test MLX Backend

on:
  pull_request:
    paths:
      - 'flash_attn/flash_attn_mlx/**'
      - 'tests/**/test*mlx*'
      - 'benchmarks/**/benchmark*mlx*'
      - '.github/workflows/test_mlx.yml'
  push:
    branches:
      - main
    paths:
      - 'flash_attn/flash_attn_mlx/**'
      - 'tests/**/test*mlx*'
      - 'benchmarks/**/benchmark*mlx*'
      - '.github/workflows/test_mlx.yml'
  workflow_dispatch:

# NOTE: GitHub-hosted macOS runners are virtualized and do NOT have Metal GPU access.
# MLX requires Metal, so full MLX testing requires self-hosted Apple Silicon runners.
# This workflow tests import/syntax only on GitHub-hosted runners.
# For full GPU tests, use self-hosted runners with label 'self-hosted-apple-silicon'.

jobs:
  # Basic syntax and import tests on GitHub-hosted runner (no Metal GPU)
  test-mlx-imports:
    runs-on: macos-14  # arm64 runner, but virtualized (no Metal)
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12"]

    name: Test MLX Imports (Python ${{ matrix.python-version }})

    steps:
      - name: Checkout
        uses: actions/checkout@v5
        with:
          submodules: recursive

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest numpy einops
          pip install mlx
          FLASH_ATTENTION_SKIP_CUDA_BUILD=TRUE pip install -e .

      - name: Verify MLX package imports
        run: |
          python -c "import mlx.core as mx; print('MLX version:', mx.__version__)"
          python -c "from flash_attn.flash_attn_mlx import flash_attn_func; print('MLX interface imported successfully')"
          # Note: is_mlx_available() may return False in virtualized environments (no Metal)
          python -c "
          from flash_attn.flash_attn_mlx import is_mlx_available
          available = is_mlx_available()
          print('MLX available (may be False in VM):', available)
          "

      - name: Run syntax/import tests only
        run: |
          # Only run tests that don't require actual GPU execution
          # The full test suite requires Metal GPU access (self-hosted runner)
          python -c "
          import sys
          print('Python:', sys.version)
          print('Testing MLX module structure...')
          
          # Test all imports work
          from flash_attn.flash_attn_mlx import (
              flash_attn_func,
              flash_attn_qkvpacked_func,
              flash_attn_kvpacked_func,
              flash_attn_with_kvcache,
          )
          print('All main interface functions imported successfully')
          
          from flash_attn.flash_attn_mlx import (
              flash_attn_varlen_func,
              flash_attn_varlen_qkvpacked_func,
              flash_attn_varlen_kvpacked_func,
          )
          print('All varlen interface functions imported successfully')
          
          print('MLX backend module structure verified!')
          "

  # Full GPU tests - only runs on self-hosted Apple Silicon runners
  # Uncomment and configure when you have self-hosted runners available
  # test-mlx-gpu:
  #   runs-on: [self-hosted, macOS, ARM64, apple-silicon]
  #   name: Test MLX GPU (Self-hosted)
  #   steps:
  #     - name: Checkout
  #       uses: actions/checkout@v5
  #     - name: Set up Python
  #       run: |
  #         python3 -m pip install --upgrade pip
  #         pip3 install pytest pytest-xdist numpy einops mlx
  #         FLASH_ATTENTION_SKIP_CUDA_BUILD=TRUE pip3 install -e .
  #     - name: Verify Metal GPU access
  #       run: |
  #         python3 -c "from flash_attn.flash_attn_mlx import is_mlx_available, get_gpu_family; print('MLX:', is_mlx_available(), 'GPU:', get_gpu_family())"
  #     - name: Run full MLX test suite
  #       run: |
  #         pytest flash_attn/flash_attn_mlx/tests/ -v --tb=short

  benchmark-mlx:
    runs-on: macos-14
    needs: test-mlx-imports
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    name: Benchmark MLX (Import Check Only)

    steps:
      - name: Checkout
        uses: actions/checkout@v5
        with:
          submodules: recursive

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest numpy einops tabulate mlx
          FLASH_ATTENTION_SKIP_CUDA_BUILD=TRUE pip install -e .

      - name: Note about benchmarks
        run: |
          echo "NOTE: Full MLX benchmarks require Metal GPU access."
          echo "GitHub-hosted runners are virtualized and don't have Metal."
          echo "For real benchmarks, run locally on Apple Silicon or use self-hosted runners."
          echo ""
          echo "Verifying benchmark script can be imported..."
          if [ -f benchmarks/benchmark_flash_attn_mlx.py ]; then
            python -c "import ast; ast.parse(open('benchmarks/benchmark_flash_attn_mlx.py').read()); print('Benchmark script syntax OK')"
          else
            echo "MLX benchmark file not found, skipping"
          fi
